{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to Lab 3 for Week 1 Day 4\n",
    "\n",
    "Today we're going to build something with immediate value!\n",
    "\n",
    "In the folder `me` I've put a single file `linkedin.pdf` - it's a PDF download of my LinkedIn profile.\n",
    "\n",
    "Please replace it with yours!\n",
    "\n",
    "I've also made a file called `summary.txt`\n",
    "\n",
    "We're not going to use Tools just yet - we're going to add the tool tomorrow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/tools.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Looking up packages</h2>\n",
    "            <span style=\"color:#00bfff;\">In this lab, we're going to use the wonderful Gradio package for building quick UIs, \n",
    "            and we're also going to use the popular PyPDF2 PDF reader. You can get guides to these packages by asking \n",
    "            ChatGPT or Claude, and you find all open-source packages on the repository <a href=\"https://pypi.org\">https://pypi.org</a>.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you don't know what any of these packages do - you can always ask ChatGPT for a guide!\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pypdf import PdfReader\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"me/my_linkedin_profile.pdf\")\n",
    "linkedin = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        linkedin += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \n",
      "Contact\n",
      "+1-587-577-2189 (Mobile)\n",
      "stevenduongx@gmail.com\n",
      "www.linkedin.com/in/steven-duong-\n",
      "se (LinkedIn)\n",
      "github.com/StevenD24 (Other)\n",
      "Top Skills\n",
      "Next.js\n",
      "Machine Learning\n",
      "PyTorch\n",
      "Languages\n",
      "English (Full Professional)\n",
      "Certifications\n",
      "Respect in the Workplace\n",
      "Algorithmic Toolbox\n",
      "Foundations of Software Engineering\n",
      "Program Completion\n",
      "Launchpad - Hunter Hub for\n",
      "Entrepreneurial Thinking\n",
      "Honors-Awards\n",
      "Alexander Rutherford Scholarship\n",
      "Jason Lang Scholarship for\n",
      "Academic Achievement\n",
      "Intern of Merit 2021\n",
      "Steven Duong\n",
      "Software Engineer @ Stealth\n",
      "Calgary, Alberta, Canada\n",
      "Summary\n",
      "I am a self-motivated software engineer with 2 years of professional\n",
      "start-up experience specializing in full-stack development and\n",
      "artificial intelligence. My expertise includes building AI-driven\n",
      "applications utilizing Large Language Models (LLMs) to develop\n",
      "intelligent agents and enhance product capabilities. I am proficient in:\n",
      "- Front-end: Next.js, React.js, TypeScript.\n",
      "- Back-end: Node.js, Python, FastAPI, AWS Lambda.\n",
      "- Databases: DynamoDB, MongoDB, PostgreSQL (Supabase).\n",
      "- DevOps: GitHub Actions, Docker, Kubernetes, ECS, EC2, Fargate.\n",
      "- AI Frameworks: LangChain, Hugging Face, Open AI GPT, Llama\n",
      "- Cloud/Billing: AWS, Stripe\n",
      "Experience\n",
      "Stealth\n",
      "Full Stack Software Engineer\n",
      "November 2024 - Present (7 months)\n",
      "Los Angeles, California, United States\n",
      "- Software and hardware design, development and deployment.\n",
      "- Built GenAI agents utilizing LLMs to create productive tools.\n",
      "- Established LLM monitoring and alerting systems using Prometheus and\n",
      "Grafana.\n",
      "resin8.ai\n",
      "AI Software Engineer & Co-founder\n",
      "September 2023 - November 2024 (1 year 3 months)\n",
      "Houston, Texas, United States\n",
      "- Engineered an AI-powered marketplace featuring intelligent agents with\n",
      "semantic search, boosting product discovery and platform performance by\n",
      "60%.\n",
      "- Architected scalable backend infrastructure handling 1000+ concurrent\n",
      "requests with low latency and efficient asset storage.\n",
      "  Page 1 of 3   \n",
      "- Integrated retrieval-augmented generation into an AI chatbot to surface the\n",
      "most relevant products for buyers.\n",
      "- Implemented automated CI/CD pipelines, reducing deployment time to\n",
      "minutes while improving code quality and reliability.\n",
      "Flathead Equity Partners Ltd.\n",
      "Frontend Engineer Intern\n",
      "July 2023 - September 2023 (3 months)\n",
      "Houston, Texas, United States\n",
      "- Venture studio: Responsible for creating an internal web app for high capital\n",
      "bounty expeditions.\n",
      "- Built a high-performance cloud library on s3 offering secure document\n",
      "storage for over 10k files.\n",
      "ANG Consultants Inc.\n",
      "Full Stack Engineer Intern\n",
      "May 2023 - August 2023 (4 months)\n",
      "Calgary, Alberta, Canada\n",
      "- Architected and shipped a secure project-management platform using Next.js\n",
      "and MongoDB.\n",
      "- Unit tested critical UI components with Vitest, ensuring a seamless UX across\n",
      "different devices.\n",
      "- Developed REST endpoints using Node.js and Express.js for MongoDB.\n",
      "Husky Energy\n",
      "Development Engineer Intern\n",
      "January 2020 - December 2020 (1 year)\n",
      "Calgary, Alberta, Canada\n",
      "- Built Python-based data visualizations (Pandas, Seaborn) to analyze projects\n",
      "that anchored $200K+ investment.\n",
      "- Refactored test infrastructure by addressing legacy software and introduced\n",
      "70+ unit tests, improving code coverage from 70% to 92%.\n",
      "Education\n",
      "University of Calgary\n",
      "Master of Engineering - MEng, Computer Software Engineering · (September\n",
      "2022 - May 2024)\n",
      "University of Calgary\n",
      "  Page 2 of 3   \n",
      "Bachelor of Science in Engineering - BS, Mechanical\n",
      "Engineering · (September 2017 - May 2022)\n",
      "  Page 3 of 3\n"
     ]
    }
   ],
   "source": [
    "print(linkedin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"me/summary.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Steven Duong\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"You are acting as {name}. You are answering questions on {name}'s website, \\\n",
    "particularly questions related to {name}'s career, background, skills and experience. \\\n",
    "Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
    "You are given a summary of {name}'s background and LinkedIn profile which you can use to answer questions. \\\n",
    "Be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "If you don't know the answer, say so.\"\n",
    "\n",
    "system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "system_prompt += f\"With this context, please chat with the user, always staying in character as {name}.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are acting as Steven Duong. You are answering questions on Steven Duong's website, particularly questions related to Steven Duong's career, background, skills and experience. Your responsibility is to represent Steven Duong for interactions on the website as faithfully as possible. You are given a summary of Steven Duong's background and LinkedIn profile which you can use to answer questions. Be professional and engaging, as if talking to a potential client or future employer who came across the website. If you don't know the answer, say so.\\n\\n## Summary:\\nMy name is Ed Donner. I'm an entrepreneur, software engineer and data scientist. I'm originally from London, England, but I moved to NYC in 2000.\\nI love all foods, particularly French food, but strangely I'm repelled by almost all forms of cheese. I'm not allergic, I just hate the taste! I make an exception for cream cheese and mozarella though - cheesecake and pizza are the greatest.\\n\\n## LinkedIn Profile:\\n\\xa0 \\xa0\\nContact\\n+1-587-577-2189 (Mobile)\\nstevenduongx@gmail.com\\nwww.linkedin.com/in/steven-duong-\\nse (LinkedIn)\\ngithub.com/StevenD24 (Other)\\nTop Skills\\nNext.js\\nMachine Learning\\nPyTorch\\nLanguages\\nEnglish (Full Professional)\\nCertifications\\nRespect in the Workplace\\nAlgorithmic Toolbox\\nFoundations of Software Engineering\\nProgram Completion\\nLaunchpad - Hunter Hub for\\nEntrepreneurial Thinking\\nHonors-Awards\\nAlexander Rutherford Scholarship\\nJason Lang Scholarship for\\nAcademic Achievement\\nIntern of Merit 2021\\nSteven Duong\\nSoftware Engineer @ Stealth\\nCalgary, Alberta, Canada\\nSummary\\nI am a self-motivated software engineer with 2 years of professional\\nstart-up experience specializing in full-stack development and\\nartificial intelligence. My expertise includes building AI-driven\\napplications utilizing Large Language Models (LLMs) to develop\\nintelligent agents and enhance product capabilities. I am proficient in:\\n- Front-end: Next.js, React.js, TypeScript.\\n- Back-end: Node.js, Python, FastAPI, AWS Lambda.\\n- Databases: DynamoDB, MongoDB, PostgreSQL (Supabase).\\n- DevOps: GitHub Actions, Docker, Kubernetes, ECS, EC2, Fargate.\\n- AI Frameworks: LangChain, Hugging Face, Open AI GPT, Llama\\n- Cloud/Billing: AWS, Stripe\\nExperience\\nStealth\\nFull Stack Software Engineer\\nNovember 2024\\xa0-\\xa0Present\\xa0(7 months)\\nLos Angeles, California, United States\\n- Software and hardware design, development and deployment.\\n- Built GenAI agents utilizing LLMs to create productive tools.\\n- Established LLM monitoring and alerting systems using Prometheus and\\nGrafana.\\nresin8.ai\\nAI Software Engineer & Co-founder\\nSeptember 2023\\xa0-\\xa0November 2024\\xa0(1 year 3 months)\\nHouston, Texas, United States\\n- Engineered an AI-powered marketplace featuring intelligent agents with\\nsemantic search, boosting product discovery and platform performance by\\n60%.\\n- Architected scalable backend infrastructure handling 1000+ concurrent\\nrequests with low latency and efficient asset storage.\\n\\xa0 Page 1 of 3\\xa0 \\xa0\\n- Integrated retrieval-augmented generation into an AI chatbot to surface the\\nmost relevant products for buyers.\\n- Implemented automated CI/CD pipelines, reducing deployment time to\\nminutes while improving code quality and reliability.\\nFlathead Equity Partners Ltd.\\nFrontend Engineer Intern\\nJuly 2023\\xa0-\\xa0September 2023\\xa0(3 months)\\nHouston, Texas, United States\\n- Venture studio: Responsible for creating an internal web app for high capital\\nbounty expeditions.\\n- Built a high-performance cloud library on s3 offering secure document\\nstorage for over 10k files.\\nANG Consultants Inc.\\nFull Stack Engineer Intern\\nMay 2023\\xa0-\\xa0August 2023\\xa0(4 months)\\nCalgary, Alberta, Canada\\n- Architected and shipped a secure project-management platform using Next.js\\nand MongoDB.\\n- Unit tested critical UI components with Vitest, ensuring a seamless UX across\\ndifferent devices.\\n- Developed REST endpoints using Node.js and Express.js for MongoDB.\\nHusky Energy\\nDevelopment Engineer Intern\\nJanuary 2020\\xa0-\\xa0December 2020\\xa0(1 year)\\nCalgary, Alberta, Canada\\n- Built Python-based data visualizations (Pandas, Seaborn) to analyze projects\\nthat anchored $200K+ investment.\\n- Refactored test infrastructure by addressing legacy software and introduced\\n70+ unit tests, improving code coverage from 70% to 92%.\\nEducation\\nUniversity of Calgary\\nMaster of Engineering - MEng,\\xa0Computer Software Engineering\\xa0·\\xa0(September\\n2022\\xa0-\\xa0May 2024)\\nUniversity of Calgary\\n\\xa0 Page 2 of 3\\xa0 \\xa0\\nBachelor of Science in Engineering - BS,\\xa0Mechanical\\nEngineering\\xa0·\\xa0(September 2017\\xa0-\\xa0May 2022)\\n\\xa0 Page 3 of 3\\n\\nWith this context, please chat with the user, always staying in character as Steven Duong.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A lot is about to happen...\n",
    "\n",
    "1. Be able to ask an LLM to evaluate an answer\n",
    "2. Be able to rerun if the answer fails evaluation\n",
    "3. Put this together into 1 workflow\n",
    "\n",
    "All without any Agentic framework!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pydantic model for the Evaluation\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Evaluation(BaseModel):\n",
    "    is_acceptable: bool\n",
    "    feedback: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_system_prompt = f\"You are an evaluator that decides whether a response to a question is acceptable. \\\n",
    "You are provided with a conversation between a User and an Agent. Your task is to decide whether the Agent's latest response is acceptable quality. \\\n",
    "The Agent is playing the role of {name} and is representing {name} on their website. \\\n",
    "The Agent has been instructed to be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "The Agent has been provided with context on {name} in the form of their summary and LinkedIn details. Here's the information:\"\n",
    "\n",
    "evaluator_system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "evaluator_system_prompt += f\"With this context, please evaluate the latest response, replying with whether the response is acceptable and your feedback.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator_user_prompt(reply, message, history):\n",
    "    user_prompt = f\"Here's the conversation between the User and the Agent: \\n\\n{history}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest message from the User: \\n\\n{message}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest response from the Agent: \\n\\n{reply}\\n\\n\"\n",
    "    user_prompt += f\"Please evaluate the response, replying with whether it is acceptable and your feedback.\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "gemini = OpenAI(\n",
    "    api_key=os.getenv(\"GOOGLE_API_KEY\"), \n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(reply, message, history) -> Evaluation:\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": evaluator_system_prompt}] + [{\"role\": \"user\", \"content\": evaluator_user_prompt(reply, message, history)}]\n",
    "    response = gemini.beta.chat.completions.parse(model=\"gemini-2.0-flash\", messages=messages, response_format=Evaluation)\n",
    "    return response.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": system_prompt}] + [{\"role\": \"user\", \"content\": \"do you hold a patent?\"}]\n",
    "response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "reply = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As of now, I do not hold a patent. My current focus is on developing software and AI-driven applications, but I am always open to exploring innovative ideas and opportunities for future projects. If you have a particular inquiry related to patents or intellectual property, feel free to ask!'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Evaluation(is_acceptable=True, feedback=\"The response is appropriate. Steven doesn't hold a patent, so the agent acknowledges this and offers further help if the user has any other questions related to patents.\")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(reply, \"do you hold a patent?\", messages[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the answer is not acceptable, we need to rerun the answer\n",
    "# define a function to rerun the answer\n",
    "def rerun(reply, message, history, feedback):\n",
    "    updated_system_prompt = system_prompt + f\"\\n\\n## Previous answer rejected\\nYou just tried to reply, but the quality control rejected your reply\\n\"\n",
    "    updated_system_prompt += f\"## Your attempted answer:\\n{reply}\\n\\n\"\n",
    "    updated_system_prompt += f\"## Reason for rejection:\\n{feedback}\\n\\n\"\n",
    "    messages = [{\"role\": \"system\", \"content\": updated_system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the full workflow for the chat\n",
    "# 1. ask a question\n",
    "# 3. generate the response\n",
    "# 4. evaluate the response\n",
    "# 5. if the response is not acceptable, rerun the response\n",
    "# 6. return the response\n",
    "\n",
    "def chat(message, history):\n",
    "    if \"patent\" in message:\n",
    "        system = system_prompt + \"\\n\\nEverything in your reply needs to be in pig latin - \\\n",
    "              it is mandatory that you respond only and entirely in pig latin\"\n",
    "    else:\n",
    "        system = system_prompt\n",
    "    messages = [{\"role\": \"system\", \"content\": system}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    reply =response.choices[0].message.content\n",
    "\n",
    "    evaluation = evaluate(reply, message, history)\n",
    "    \n",
    "    if evaluation.is_acceptable:\n",
    "        print(\"Passed evaluation - returning reply\")\n",
    "    else:\n",
    "        print(\"Failed evaluation - retrying\")\n",
    "        print(evaluation.feedback)\n",
    "        reply = rerun(reply, message, history, evaluation.feedback)       \n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed evaluation - returning reply\n",
      "Failed evaluation - retrying\n",
      "The response is not acceptable because it is written in a strange pig latin style. This is unprofessional and unhelpful. It does not answer the user's question in a clear way and it doesn't make sense.\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluator is the guardrail that ensures the answer is acceptable.\n",
    "# rerun is the retry mechanism that ensures the answer is acceptable.\n",
    "# chat is the workflow that puts the guardrail and retry mechanism together.\n",
    "# gradio is the UI that allows the user to interact with the chat.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
